# AI 関連

## ベクトル検索の基本

ベクトルのコサイン類似度の計算はベクトル DB の機能を利用するのが高率的。わざわざアプリ側で計算しない。
保存したベクトルをさらに加工して、次元を落とすことでRDBにおけるインデックスと似た効果を持たせる技術も登場している。

### 基本的な流れ

1. 正規化
   - 例: neologdn を利用して、全角英数字を半角に変換、全角スペースを半角スペースに変換、改行コードを統一など
2. トークン化
   - 例: MeCab や Sudachi などの形態素解析器を利用して、文章を単語やフレーズに分割
3. ベクトル化
   - 例: SentenceTransformer や FastText などの事前学習済みモデルを利用して、トークン化された単語やフレーズをベクトルに変換
4. ベクトルの保存
   - 例: PostgreSQL の pgvector 拡張を利用して、ベクトルをデータベースに保存
5. 検索クエリをベクトル化
   - 例: ユーザーの検索クエリを同様にベクトル化
6. 類似度計算
   - 例: ベクトル DB の機能を利用して、保存されたベクトルと検索クエリのベクトルとのコサイン類似度を計算
7. 結果の取得
   - 例: 類似度が高い順に結果を取得し、ユーザーに返す

## ベクトル DB の選定

ベクトルに特化したDBも存在はするものの、発展途上であり、小規模においてはRDBを利用するのが現実的である。
[参考](https://zenn.dev/rwcolinpeng/articles/45632994cf8bc1)

## pgvector

PostgreSQL の拡張で、ベクトルデータを扱えるようにするもの。
テーブル設定時に `vector(1024)` のように次元数を指定することで、ベクトルを保存できる。
ただし、このベクトルの次元数は固定であり、異なる次元数のベクトルを同じカラムに保存することはできない。

### 導入方法

基本的には以下のサイトを参考にした。alpine 指定によると思われるえらーは AI に聞いて解決した。
[参考](https://qiita.com/naozo-se/items/0730c8ea650eaa0d51c8)

## 計算インフラを考慮したアーキテクチャ選定 3 パターン

1. 通常の EC2, ECS 上で自然言語処理を行う（某インフラ構成と同様）
2. Lambda などのサーバーレスで自然言語処理を行う
   1. パターン1: そのまま自然言語処理を行う（Python, SentenceTransformer, モデルにより重いコールドスタートが発生）
   2. パターン2: ONNX などのコンテナを利用して、モデルを事前にロードしておくことでコールドスタートを回避する
3. SageMaker などのマネージドサービスを利用して自然言語処理を行う

## ONNX

ONNX（Open Neural Network Exchange）は、異なるフレームワーク間でモデルを共有するためのオープンなフォーマット。これにより、PyTorch や TensorFlow などの異なるフレームワークでトレーニングされたモデルを、他のフレームワークで推論に使用できる。ただし、基本的に静的な計算グラフであるため、動的なモデルには向かないため、主な用途はベクトル化や分類、自然言語生成といった推論に限られる。モデルの学習・訓練、データの前処理、ベクトル間の類似度計算などは通常のフレームワークで行うことが求められる。

### ONNX のメリット

- 異なるフレームワーク間での互換性が高い
- モデルの推論速度が向上することがある
- モデルのサイズが小さくなることがある
- Python 以外の言語（C++, Java など）でも利用可能

### ONNX のデメリット

- 動的な計算グラフには対応していないため、特定のモデルには適用できない
- 一部のフレームワーク固有の機能やオペレーションがサポートされていないことがある
- モデルの変換プロセスが必要

## SageMaker

SageMaker が EC2 などと比較して優れている点は

運用・管理の簡素化

### 自動スケーリング

トラフィックに応じた自動的なインスタンス追加・削除
EC2では手動設定が必要なオートスケーリンググループが自動構築

### マネージドインフラ

OS、Python環境、機械学習ライブラリの管理が不要
セキュリティパッチやアップデートが自動適用

### SageMakerでのモデルデプロイ例

predictor = model.deploy(
    initial_instance_count=1,
    instance_type='ml.t3.medium',
    auto_scaling_enabled=True
)
